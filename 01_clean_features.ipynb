{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1b2634-995c-4f79-a85c-dae02d26e963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment\n",
      "Employed, full-time                                                         39041\n",
      "Independent contractor, freelancer, or self-employed                         4846\n",
      "Student, full-time                                                           4709\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed     3557\n",
      "Not employed, but looking for work                                           2341\n",
      "Name: count, dtype: int64\n",
      "Rows after filter → (0, 114)\n"
     ]
    }
   ],
   "source": [
    "# Cell A  – filter to full-time devs\n",
    "print(df['Employment'].value_counts(dropna=False).head())   # see categories\n",
    "\n",
    "df = df[df['Employment'] == 'Employed full-time'].copy()\n",
    "print(\"Rows after filter →\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf50cce5-8cf0-4187-b99a-fa158d966a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Cell B  – map “dissatisfied” answers to 1 (burned-out), the rest to 0\n",
    "dissat = {'Very dissatisfied', 'Slightly dissatisfied'}\n",
    "\n",
    "def burnout_flag(answer):\n",
    "    if pd.isna(answer):\n",
    "        return pd.NA          # keep as missing for now\n",
    "    return 1 if answer in dissat else 0\n",
    "\n",
    "df['burnout'] = df['JobSat'].apply(burnout_flag)\n",
    "\n",
    "print(df['burnout'].value_counts(dropna=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257c3c3d-673b-4391-8d8f-9c59cc308059",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AI_Search_Use'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'AI_Search_Use'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell C – peek at the raw answers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAI_Search_Use\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts(dropna=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'AI_Search_Use'"
     ]
    }
   ],
   "source": [
    "# Cell C – peek at the raw answers\n",
    "df['AI_Search_Use'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f610ee92-f992-49c0-98ae-a8d347a8add6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AISearchDevHaveWorkedWith',\n",
       " 'AISearchDevWantToWorkWith',\n",
       " 'AISearchDevAdmired',\n",
       " 'AISelect',\n",
       " 'AISent',\n",
       " 'AIBen',\n",
       " 'AIAcc',\n",
       " 'AIComplex',\n",
       " 'AIToolCurrently Using',\n",
       " 'AIToolInterested in Using',\n",
       " 'AIToolNot interested in Using',\n",
       " 'AINextMuch more integrated',\n",
       " 'AINextNo change',\n",
       " 'AINextMore integrated',\n",
       " 'AINextLess integrated',\n",
       " 'AINextMuch less integrated',\n",
       " 'AIThreat',\n",
       " 'AIEthics',\n",
       " 'AIChallenges',\n",
       " 'TimeSearching']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List any columns that mention \"AI\" or \"Search\" so we can see the exact spelling\n",
    "[col for col in df.columns if 'AI' in col or 'Search' in col][:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83fe6ae9-3e06-4127-84e6-f063a9bfd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_FREQ_COL = 'AI Search Frequency'   # ← put your column name here exactly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e93184-1f6d-4042-a884-38401c912204",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AI Search Frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'AI Search Frequency'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m freq_map = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMultiple times per day\u001b[39m\u001b[33m'\u001b[39m:        \u001b[32m3\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mA few times per week\u001b[39m\u001b[33m'\u001b[39m:          \u001b[32m2\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNever\u001b[39m\u001b[33m'\u001b[39m:                         \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mai_freq\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAI_FREQ_COL\u001b[49m\u001b[43m]\u001b[49m.map(freq_map)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Quick check\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[[AI_FREQ_COL, \u001b[33m'\u001b[39m\u001b[33mai_freq\u001b[39m\u001b[33m'\u001b[39m]].head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'AI Search Frequency'"
     ]
    }
   ],
   "source": [
    "freq_map = {\n",
    "    'Multiple times per day':        3,\n",
    "    'A few times per week':          2,\n",
    "    'A few times per month':         1,\n",
    "    'Less than once per month':      0,\n",
    "    'Never':                         0\n",
    "}\n",
    "\n",
    "df['ai_freq'] = df[AI_FREQ_COL].map(freq_map)\n",
    "\n",
    "# Quick check\n",
    "print(df[[AI_FREQ_COL, 'ai_freq']].head())\n",
    "print(df['ai_freq'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba46a20-7ae5-4df5-9a84-4928abfe114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns that mention AI: 20\n",
      " • MainBranch\n",
      " • AISearchDevHaveWorkedWith\n",
      " • AISearchDevWantToWorkWith\n",
      " • AISearchDevAdmired\n",
      " • AISelect\n",
      " • AISent\n",
      " • AIBen\n",
      " • AIAcc\n",
      " • AIComplex\n",
      " • AIToolCurrently Using\n",
      " • AIToolInterested in Using\n",
      " • AIToolNot interested in Using\n",
      " • AINextMuch more integrated\n",
      " • AINextNo change\n",
      " • AINextMore integrated\n",
      " • AINextLess integrated\n",
      " • AINextMuch less integrated\n",
      " • AIThreat\n",
      " • AIEthics\n",
      " • AIChallenges\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ai_cols = [c for c in df.columns if re.search(r'ai', c, flags=re.I)]\n",
    "print(\"Columns that mention AI:\", len(ai_cols))\n",
    "for c in ai_cols:\n",
    "    print(\" •\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f06d5c-68bb-4aa1-917e-c40ddec0cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [AIToolCurrently Using, ai_freq]\n",
      "Index: []\n",
      "\n",
      "ai_freq value counts:\n",
      " Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "AI_TOOL_COL = 'AIToolCurrently Using'          # exact column name\n",
    "\n",
    "def count_tools(cell):\n",
    "    \"\"\"Return number of AI tools listed (0 if NaN).\"\"\"\n",
    "    if pd.isna(cell) or cell.strip() == '':\n",
    "        return 0\n",
    "    # split on comma and count non-empty parts\n",
    "    return len([t for t in cell.split(',') if t.strip()])\n",
    "\n",
    "df['ai_freq'] = df[AI_TOOL_COL].apply(count_tools)\n",
    "\n",
    "# Quick sanity-check\n",
    "print(df[[AI_TOOL_COL, 'ai_freq']].head(10))\n",
    "print(\"\\nai_freq value counts:\\n\", df['ai_freq'].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc33d8fc-594d-44c8-9b4b-a68e1e01debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape: (0, 116)\n",
      "Empty DataFrame\n",
      "Columns: [ResponseId, MainBranch, Age, Employment, RemoteWork, Check, CodingActivities, EdLevel, LearnCode, LearnCodeOnline, TechDoc, YearsCode, YearsCodePro, DevType, OrgSize, PurchaseInfluence, BuyNewTool, BuildvsBuy, TechEndorse, Country, Currency, CompTotal, LanguageHaveWorkedWith, LanguageWantToWorkWith, LanguageAdmired, DatabaseHaveWorkedWith, DatabaseWantToWorkWith, DatabaseAdmired, PlatformHaveWorkedWith, PlatformWantToWorkWith, PlatformAdmired, WebframeHaveWorkedWith, WebframeWantToWorkWith, WebframeAdmired, EmbeddedHaveWorkedWith, EmbeddedWantToWorkWith, EmbeddedAdmired, MiscTechHaveWorkedWith, MiscTechWantToWorkWith, MiscTechAdmired, ToolsTechHaveWorkedWith, ToolsTechWantToWorkWith, ToolsTechAdmired, NEWCollabToolsHaveWorkedWith, NEWCollabToolsWantToWorkWith, NEWCollabToolsAdmired, OpSysPersonal use, OpSysProfessional use, OfficeStackAsyncHaveWorkedWith, OfficeStackAsyncWantToWorkWith, OfficeStackAsyncAdmired, OfficeStackSyncHaveWorkedWith, OfficeStackSyncWantToWorkWith, OfficeStackSyncAdmired, AISearchDevHaveWorkedWith, AISearchDevWantToWorkWith, AISearchDevAdmired, NEWSOSites, SOVisitFreq, SOAccount, SOPartFreq, SOHow, SOComm, AISelect, AISent, AIBen, AIAcc, AIComplex, AIToolCurrently Using, AIToolInterested in Using, AIToolNot interested in Using, AINextMuch more integrated, AINextNo change, AINextMore integrated, AINextLess integrated, AINextMuch less integrated, AIThreat, AIEthics, AIChallenges, TBranch, ICorPM, WorkExp, Knowledge_1, Knowledge_2, Knowledge_3, Knowledge_4, Knowledge_5, Knowledge_6, Knowledge_7, Knowledge_8, Knowledge_9, Frequency_1, Frequency_2, Frequency_3, TimeSearching, TimeAnswering, Frustration, ProfessionalTech, ProfessionalCloud, ProfessionalQuestion, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current shape:\", df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895a21f7-94c3-4721-9f8c-32b7a7f47e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Employment'] == 'Employed full-time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d85121-2dd2-463b-a2a3-1623146c9193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employment\n",
       "Employed, full-time                                                                        39041\n",
       "Independent contractor, freelancer, or self-employed                                        4846\n",
       "Student, full-time                                                                          4709\n",
       "Employed, full-time;Independent contractor, freelancer, or self-employed                    3557\n",
       "Not employed, but looking for work                                                          2341\n",
       "Employed, part-time                                                                         1266\n",
       "Student, full-time;Employed, part-time                                                      1115\n",
       "Employed, full-time;Student, full-time                                                       897\n",
       "Employed, full-time;Student, part-time                                                       839\n",
       "Student, full-time;Not employed, but looking for work                                        686\n",
       "Not employed, and not looking for work                                                       633\n",
       "Student, part-time;Employed, part-time                                                       558\n",
       "I prefer not to say                                                                          546\n",
       "Retired                                                                                      525\n",
       "Student, part-time                                                                           494\n",
       "Independent contractor, freelancer, or self-employed;Employed, part-time                     401\n",
       "Not employed, but looking for work;Independent contractor, freelancer, or self-employed      383\n",
       "Student, full-time;Independent contractor, freelancer, or self-employed                      375\n",
       "Student, full-time;Not employed, and not looking for work                                    311\n",
       "Employed, full-time;Employed, part-time                                                      212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_csv(\"data/raw/so_survey_2024.csv\", low_memory=False)   # load fresh\n",
    "df_orig['Employment'].value_counts(dropna=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eae0555-9a18-4d93-bbc1-d0d4ca6e5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig[df_orig['Employment'] == 'I am employed full-time'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27dd32e1-7a52-489a-9acc-e91423741213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filter: (0, 114)\n"
     ]
    }
   ],
   "source": [
    "print(\"After filter:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e2dc2b-bf48-49a1-9eba-8a0ba7d6f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [AIToolCurrently Using, ai_freq]\n",
      "Index: []\n",
      "\n",
      "ai_freq value counts:\n",
      " Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "AI_TOOL_COL = 'AIToolCurrently Using'   # same as before\n",
    "\n",
    "def count_tools(cell):\n",
    "    if pd.isna(cell) or cell.strip() == '':\n",
    "        return 0\n",
    "    return len([t for t in cell.split(',') if t.strip()])\n",
    "\n",
    "df['ai_freq'] = df[AI_TOOL_COL].apply(count_tools)\n",
    "\n",
    "print(df[[AI_TOOL_COL, 'ai_freq']].head())\n",
    "print(\"\\nai_freq value counts:\\n\", df['ai_freq'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7860c329-9dae-4e5b-867d-a4fdb6a16180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment\n",
      "Employed, full-time                                                         39041\n",
      "Independent contractor, freelancer, or self-employed                         4846\n",
      "Student, full-time                                                           4709\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed     3557\n",
      "Not employed, but looking for work                                           2341\n",
      "Employed, part-time                                                          1266\n",
      "Student, full-time;Employed, part-time                                       1115\n",
      "Employed, full-time;Student, full-time                                        897\n",
      "Employed, full-time;Student, part-time                                        839\n",
      "Student, full-time;Not employed, but looking for work                         686\n",
      "Not employed, and not looking for work                                        633\n",
      "Student, part-time;Employed, part-time                                        558\n",
      "I prefer not to say                                                           546\n",
      "Retired                                                                       525\n",
      "Student, part-time                                                            494\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reload only the Employment column so we see real spellings\n",
    "df_orig = pd.read_csv(\"data/raw/so_survey_2024.csv\", usecols=['Employment'])\n",
    "print(df_orig['Employment'].value_counts(dropna=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004845d0-680f-48dc-944f-fe8f6e80bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filter: (39041, 114)\n"
     ]
    }
   ],
   "source": [
    "# Reload full dataset (skip if df_orig already has all columns)\n",
    "df = pd.read_csv(\"data/raw/so_survey_2024.csv\", low_memory=False)\n",
    "\n",
    "# Exact-match option\n",
    "df = df[df['Employment'] == 'Employed, full-time'].copy()\n",
    "\n",
    "# OR safer contains-match\n",
    "# df = df[df['Employment'].str.contains('Employed, full', case=False, na=False)].copy()\n",
    "\n",
    "print(\"After filter:\", df.shape)        # expect ~39 k rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dbfe32e-44c4-4b69-ae1f-a96c22f1f240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AIToolCurrently Using  ai_freq\n",
      "0                   NaN        0\n",
      "1                   NaN        0\n",
      "2                   NaN        0\n",
      "6                   NaN        0\n",
      "8                   NaN        0\n",
      "\n",
      "ai_freq value counts:\n",
      " ai_freq\n",
      "0    18441\n",
      "1    20600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "AI_TOOL_COL = 'AIToolCurrently Using'   # column already exists\n",
    "\n",
    "def count_tools(cell):\n",
    "    if pd.isna(cell) or cell.strip() == '':\n",
    "        return 0\n",
    "    return len([t for t in cell.split(',') if t.strip()])\n",
    "\n",
    "df['ai_freq'] = df[AI_TOOL_COL].apply(count_tools)\n",
    "\n",
    "print(df[[AI_TOOL_COL, 'ai_freq']].head())\n",
    "print(\"\\nai_freq value counts:\\n\", df['ai_freq'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c192766f-69c4-4f81-9a51-595fc01c98c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RemoteWorkStatus'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'RemoteWorkStatus'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33myears_code\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df[\u001b[33m'\u001b[39m\u001b[33mYearsCodePro\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Remote-work encoding (simple category → integer code)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mremote_code\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRemoteWorkStatus\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m).cat.codes\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# If your column is named just 'Remote' or 'RemoteWork', adjust the name above.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Quick peek\u001b[39;00m\n\u001b[32m     10\u001b[39m df[[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33myears_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mremote_code\u001b[39m\u001b[33m'\u001b[39m]].describe().T\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'RemoteWorkStatus'"
     ]
    }
   ],
   "source": [
    "# Safe numeric conversions\n",
    "df['age']        = pd.to_numeric(df['Age'],          errors='coerce')\n",
    "df['years_code'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Remote-work encoding (simple category → integer code)\n",
    "df['remote_code'] = df['RemoteWorkStatus'].astype('category').cat.codes\n",
    "# If your column is named just 'Remote' or 'RemoteWork', adjust the name above.\n",
    "\n",
    "# Quick peek\n",
    "df[['age', 'years_code', 'remote_code']].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39fca3ab-80c9-482f-bcde-9ac6588e0a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RemoteWork']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df.columns if 'remote' in c.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "343a0f84-aa40-4649-a3b0-8aa872df58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_COL = 'RemoteWork'       # ← put your exact column name here\n",
    "\n",
    "df['remote_code'] = (\n",
    "    df[REMOTE_COL]\n",
    "      .astype('category')        # turn text → pandas category\n",
    "      .cat.codes                 # integer codes (-1 means NaN)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e46d23c-5d14-4ae5-b2fe-5526ab590e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_code</th>\n",
       "      <td>33841.0</td>\n",
       "      <td>10.834195</td>\n",
       "      <td>8.607691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remote_code</th>\n",
       "      <td>39041.0</td>\n",
       "      <td>0.894521</td>\n",
       "      <td>0.878063</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count       mean       std  min  25%  50%   75%   max\n",
       "age              0.0        NaN       NaN  NaN  NaN  NaN   NaN   NaN\n",
       "years_code   33841.0  10.834195  8.607691  1.0  4.0  8.0  15.0  50.0\n",
       "remote_code  39041.0   0.894521  0.878063 -1.0  0.0  1.0   2.0   2.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['age', 'years_code', 'remote_code']].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af55a5ef-b9bc-41e7-92fd-233f6ae59066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'LanguageHaveWorkedWith',\n",
       " 'LanguageWantToWorkWith',\n",
       " 'LanguageAdmired',\n",
       " 'age']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df.columns if 'age' in col.lower()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "339092e0-e7bb-4bb0-a970-4f8ddfe6beb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "25-34 years old       17282\n",
       "35-44 years old       10775\n",
       "18-24 years old        4839\n",
       "45-54 years old        4234\n",
       "55-64 years old        1600\n",
       "65 years or older       182\n",
       "Prefer not to say        71\n",
       "Under 18 years old       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78ff0ad7-becc-4060-afea-71c7ca60191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = {\n",
    "    'Under 18'         : 16,   # midpoint of 0-18\n",
    "    '18-24'            : 21,\n",
    "    '25-34'            : 29.5,\n",
    "    '35-44'            : 39.5,\n",
    "    '45-54'            : 49.5,\n",
    "    '55-64'            : 59.5,\n",
    "    '65 or older'      : 70,\n",
    "    'Prefer not to say': pd.NA\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf1aba07-cf85-49c6-aab2-b3060839f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       0\n",
      "unique      0\n",
      "top       NaN\n",
      "freq      NaN\n",
      "Name: age, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['age'] = df['Age'].map(age_map)\n",
    "print(df['age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25b60cd6-6414-46ce-8c2d-b37de65645d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>years_code</th>\n",
       "      <td>33841.0</td>\n",
       "      <td>10.834195</td>\n",
       "      <td>8.607691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean       std  min  25%  50%   75%   max\n",
       "years_code  33841.0  10.834195  8.607691  1.0  4.0  8.0  15.0  50.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['years_code'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "df[['age', 'years_code']].describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84eda632-71e3-44e5-ae1d-932de127304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remote_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   remote_code\n",
       "0            2\n",
       "1            2\n",
       "2            2\n",
       "6            2\n",
       "8            1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['remote_code'] = (\n",
    "    df['RemoteWork']\n",
    "      .astype('category')\n",
    "      .cat.codes        # 0,1,2…  ; -1 means missing\n",
    ")\n",
    "\n",
    "df[['remote_code']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddba740b-2e54-4a39-80ad-8d79c3c4f45c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['burnout'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mburnout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mai_freq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myears_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mremote_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['burnout'] not in index\""
     ]
    }
   ],
   "source": [
    "df[['burnout', 'ai_freq', 'age', 'years_code', 'remote_code']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecf3b962-31d8-4f6e-841c-ecacb4139ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Age strings (8):\n",
      "'Under 18 years old'\n",
      "'35-44 years old'\n",
      "'45-54 years old'\n",
      "'25-34 years old'\n",
      "'55-64 years old'\n",
      "'18-24 years old'\n",
      "'65 years or older'\n",
      "'Prefer not to say'\n"
     ]
    }
   ],
   "source": [
    "unique_ages = df['Age'].dropna().unique().tolist()\n",
    "print(\"Unique Age strings ({}):\".format(len(unique_ages)))\n",
    "for v in unique_ages:\n",
    "    print(repr(v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9259e01a-086c-46ef-8b05-048ce25a6af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m age_map = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mUnder 18 years old\u001b[39m\u001b[33m'\u001b[39m : \u001b[32m16\u001b[39m,      \u001b[38;5;66;03m# midpoint of 0-18\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m18-24 years old\u001b[39m\u001b[33m'\u001b[39m    : \u001b[32m21\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPrefer not to say\u001b[39m\u001b[33m'\u001b[39m  : pd.NA    \u001b[38;5;66;03m# keep as missing\u001b[39;00m\n\u001b[32m     10\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAge\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mage_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m].describe())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6662\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6656\u001b[39m     results = [\n\u001b[32m   6657\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6658\u001b[39m     ]\n\u001b[32m   6660\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6661\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6663\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "age_map = {\n",
    "    'Under 18 years old' : 16,      # midpoint of 0-18\n",
    "    '18-24 years old'    : 21,\n",
    "    '25-34 years old'    : 29.5,\n",
    "    '35-44 years old'    : 39.5,\n",
    "    '45-54 years old'    : 49.5,\n",
    "    '55-64 years old'    : 59.5,\n",
    "    '65 years or older'  : 70,\n",
    "    'Prefer not to say'  : pd.NA    # keep as missing\n",
    "}\n",
    "\n",
    "df['age'] = df['Age'].map(age_map).astype(float)\n",
    "print(df['age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4d80bf8-5d4d-4d45-8460-52eca2eb9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    38970.000000\n",
      "mean        34.783205\n",
      "std          9.851567\n",
      "min         16.000000\n",
      "25%         29.500000\n",
      "50%         29.500000\n",
      "75%         39.500000\n",
      "max         70.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "age_map = {\n",
    "    'Under 18 years old' : 16,\n",
    "    '18-24 years old'    : 21,\n",
    "    '25-34 years old'    : 29.5,\n",
    "    '35-44 years old'    : 39.5,\n",
    "    '45-54 years old'    : 49.5,\n",
    "    '55-64 years old'    : 59.5,\n",
    "    '65 years or older'  : 70,\n",
    "    'Prefer not to say'  : np.nan       # ← changed\n",
    "}\n",
    "\n",
    "df['age'] = df['Age'].map(age_map).astype(float)\n",
    "print(df['age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a756e167-ea35-4d30-b8cd-ef4a3d0b60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    38970.000000\n",
      "mean        34.783205\n",
      "std          9.851567\n",
      "min         16.000000\n",
      "25%         29.500000\n",
      "50%         29.500000\n",
      "75%         39.500000\n",
      "max         70.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "age_map['Prefer not to say'] = pd.NA     # keep as-is\n",
    "\n",
    "df['age'] = (\n",
    "    df['Age'].map(age_map)               # object dtype w/ pd.NA\n",
    "          .pipe(pd.to_numeric, errors='coerce')  # converts pd.NA → NaN, rest → float\n",
    ")\n",
    "print(df['age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eff44cb7-c979-498c-8e06-a9c1c709b03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['burnout'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mburnout\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mai_freq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myears_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mremote_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['burnout'] not in index\""
     ]
    }
   ],
   "source": [
    "df[['burnout', 'ai_freq', 'age', 'years_code', 'remote_code']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab648fde-ec1b-445a-bf60-2e6b0e214977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobSat\n",
       "NaN     16504\n",
       "8.0      5834\n",
       "7.0      5032\n",
       "6.0      2924\n",
       "9.0      2824\n",
       "10.0     1592\n",
       "5.0      1533\n",
       "3.0       900\n",
       "4.0       848\n",
       "2.0       599\n",
       "0.0       242\n",
       "1.0       209\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['JobSat'].value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ec42104-455c-4054-b5bc-4deee00784c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "burnout\n",
       "0       20587\n",
       "<NA>    16504\n",
       "1        1950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['burnout'] = df['JobSat'].apply(\n",
    "    lambda x: 1 if pd.notna(x) and x <= 3 else 0 if pd.notna(x) else pd.NA\n",
    ")\n",
    "\n",
    "df['burnout'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd760d99-0b21-4d72-b06e-381cb7048042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AIToolCurrently Using',\n",
       " 'AIToolInterested in Using',\n",
       " 'AIToolNot interested in Using']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df.columns if 'AITool' in c or 'AI Tool' in c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "030902a6-572c-461f-a013-d3f404411fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai_freq\n",
       "0    18441\n",
       "1    20600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tools(cell):\n",
    "    if pd.isna(cell) or cell.strip() == '':\n",
    "        return 0\n",
    "    # split on commas, drop empty pieces, count what’s left\n",
    "    return len([t for t in cell.split(',') if t.strip()])\n",
    "\n",
    "df['ai_freq'] = df['AIToolCurrently Using'].apply(count_tools)\n",
    "\n",
    "# Quick check\n",
    "df['ai_freq'].value_counts(dropna=False).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "604722ab-bb19-4bf8-8e08-ab8f00c24950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "25-34 years old       17282\n",
       "35-44 years old       10775\n",
       "18-24 years old        4839\n",
       "45-54 years old        4234\n",
       "55-64 years old        1600\n",
       "65 years or older       182\n",
       "Prefer not to say        71\n",
       "Under 18 years old       58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d86732aa-373f-41bd-a0bf-547490c3473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    38970.000000\n",
      "mean        34.783205\n",
      "std          9.851567\n",
      "min         16.000000\n",
      "25%         29.500000\n",
      "50%         29.500000\n",
      "75%         39.500000\n",
      "max         70.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "age_map = {\n",
    "    'Under 18 years old' : 16.0,   # midpoint of 0-18\n",
    "    '18-24 years old'    : 21.0,\n",
    "    '25-34 years old'    : 29.5,\n",
    "    '35-44 years old'    : 39.5,\n",
    "    '45-54 years old'    : 49.5,\n",
    "    '55-64 years old'    : 59.5,\n",
    "    '65 years or older'  : 70.0,\n",
    "    'Prefer not to say'  : np.nan  # keep as missing\n",
    "}\n",
    "\n",
    "df['age'] = df['Age'].map(age_map)\n",
    "\n",
    "# sanity-check\n",
    "print(df['age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6690490a-bd40-4d6a-a05b-c502ddca09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    33841.000000\n",
      "mean        10.834195\n",
      "std          8.607691\n",
      "min          1.000000\n",
      "25%          4.000000\n",
      "50%          8.000000\n",
      "75%         15.000000\n",
      "max         50.000000\n",
      "Name: years_code, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['years_code'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# quick summary\n",
    "print(df['years_code'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3daace4f-846e-47ff-8ef5-8d714345890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RemoteWork', 'remote_code']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in df.columns if 'remote' in c.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc386e05-7091-4cfc-a780-7026c1a4c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw RemoteWork values:\n",
      "RemoteWork\n",
      "Hybrid (some remote, some in-person)    17281\n",
      "Remote                                  13193\n",
      "In-person                                8552\n",
      "NaN                                        15\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "remote_code preview:\n",
      "remote_code\n",
      "-1       15\n",
      " 0    17281\n",
      " 1     8552\n",
      " 2    13193\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw RemoteWork values:\")\n",
    "print(df['RemoteWork'].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "print(\"remote_code preview:\")\n",
    "print(df['remote_code'].value_counts(dropna=False).sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4774ec0a-d1d7-4c22-8b9c-344f7527367e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m Path(\u001b[33m\"\u001b[39m\u001b[33mdata/processed\u001b[39m\u001b[33m\"\u001b[39m).mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed/so_clean.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅  Saved to data/processed/so_clean.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3118\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3037\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3038\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3039\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3114\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3115\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3116\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\burnout-ai-study\\venv\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# make sure the processed folder exists\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save\n",
    "df.to_parquet(\"data/processed/so_clean.parquet\", index=False)\n",
    "\n",
    "print(\"✅  Saved to data/processed/so_clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabafd6d-8f6c-4af7-9d4f-4dc798bdcfd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      2\u001b[39m Path(\u001b[33m\"\u001b[39m\u001b[33mdata/processed\u001b[39m\u001b[33m\"\u001b[39m).mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf\u001b[49m.to_parquet(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/so_clean.parquet\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅  Saved to data/processed/so_clean.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(\"data/processed/so_clean.parquet\", index=False)\n",
    "print(\"✅  Saved to data/processed/so_clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8537c620-8ead-4868-b9aa-09a2fbf3cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved to data/processed/so_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Load raw CSV\n",
    "df = pd.read_csv(\"data/raw/so_survey_2024.csv\", low_memory=False)\n",
    "\n",
    "# 2. Keep full-time employees only\n",
    "df = df[df['Employment'] == 'Employed, full-time'].copy()\n",
    "\n",
    "# 3. burnout flag\n",
    "df['burnout'] = df['JobSat'].apply(\n",
    "    lambda x: 1 if pd.notna(x) and x <= 3 else 0 if pd.notna(x) else np.nan\n",
    ")\n",
    "\n",
    "# 4. ai_freq\n",
    "def count_tools(cell):\n",
    "    if pd.isna(cell) or cell.strip() == '':\n",
    "        return 0\n",
    "    return len([t for t in cell.split(',') if t.strip()])\n",
    "df['ai_freq'] = df['AIToolCurrently Using'].apply(count_tools)\n",
    "\n",
    "# 5. age mapping\n",
    "age_map = {\n",
    "    'Under 18 years old': 16.0, '18-24 years old': 21.0, '25-34 years old': 29.5,\n",
    "    '35-44 years old': 39.5, '45-54 years old': 49.5, '55-64 years old': 59.5,\n",
    "    '65 years or older': 70.0, 'Prefer not to say': np.nan\n",
    "}\n",
    "df['age'] = df['Age'].map(age_map)\n",
    "\n",
    "# 6. years_code & remote_code\n",
    "df['years_code']  = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "df['remote_code'] = df['RemoteWork'].astype('category').cat.codes\n",
    "\n",
    "# 7. Save parquet\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(\"data/processed/so_clean.parquet\", index=False)\n",
    "print(\"✅  Saved to data/processed/so_clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1038c95-8bd0-4281-a396-00735cb79d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
